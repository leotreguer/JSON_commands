{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d987f96-185f-4a59-a20c-760e2521a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b936fe8-218f-412a-b7c3-ccfc2c97ac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['project', 'version', 'traces'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>version</th>\n",
       "      <th>traces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0001', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0002', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0003', 'user_query': 'Tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0004', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0005', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0006', 'user_query': 'Expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0007', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0008', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0009', 'user_query': 'What...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0010', 'user_query': 'Expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0011', 'user_query': 'Tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0012', 'user_query': 'What...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0013', 'user_query': 'What...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0014', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0015', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0016', 'user_query': 'What...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0017', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0018', 'user_query': 'What...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0019', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0020', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0021', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0022', 'user_query': 'Expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0023', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0024', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0025', 'user_query': 'Expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0026', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0027', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0028', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0029', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0030', 'user_query': 'What...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0031', 'user_query': 'Tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0032', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0033', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0034', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0035', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0036', 'user_query': 'Expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0037', 'user_query': 'Tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0038', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0039', 'user_query': 'What...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0040', 'user_query': 'What...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0041', 'user_query': 'Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0042', 'user_query': 'Expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0043', 'user_query': 'Expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0044', 'user_query': 'Expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0045', 'user_query': 'Expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0046', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0047', 'user_query': 'Tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0048', 'user_query': 'Expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0049', 'user_query': 'Tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'trace_id': 'trace_0050', 'user_query': 'Expl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    project  version  \\\n",
       "0   LLM Evaluation Exercise        1   \n",
       "1   LLM Evaluation Exercise        1   \n",
       "2   LLM Evaluation Exercise        1   \n",
       "3   LLM Evaluation Exercise        1   \n",
       "4   LLM Evaluation Exercise        1   \n",
       "5   LLM Evaluation Exercise        1   \n",
       "6   LLM Evaluation Exercise        1   \n",
       "7   LLM Evaluation Exercise        1   \n",
       "8   LLM Evaluation Exercise        1   \n",
       "9   LLM Evaluation Exercise        1   \n",
       "10  LLM Evaluation Exercise        1   \n",
       "11  LLM Evaluation Exercise        1   \n",
       "12  LLM Evaluation Exercise        1   \n",
       "13  LLM Evaluation Exercise        1   \n",
       "14  LLM Evaluation Exercise        1   \n",
       "15  LLM Evaluation Exercise        1   \n",
       "16  LLM Evaluation Exercise        1   \n",
       "17  LLM Evaluation Exercise        1   \n",
       "18  LLM Evaluation Exercise        1   \n",
       "19  LLM Evaluation Exercise        1   \n",
       "20  LLM Evaluation Exercise        1   \n",
       "21  LLM Evaluation Exercise        1   \n",
       "22  LLM Evaluation Exercise        1   \n",
       "23  LLM Evaluation Exercise        1   \n",
       "24  LLM Evaluation Exercise        1   \n",
       "25  LLM Evaluation Exercise        1   \n",
       "26  LLM Evaluation Exercise        1   \n",
       "27  LLM Evaluation Exercise        1   \n",
       "28  LLM Evaluation Exercise        1   \n",
       "29  LLM Evaluation Exercise        1   \n",
       "30  LLM Evaluation Exercise        1   \n",
       "31  LLM Evaluation Exercise        1   \n",
       "32  LLM Evaluation Exercise        1   \n",
       "33  LLM Evaluation Exercise        1   \n",
       "34  LLM Evaluation Exercise        1   \n",
       "35  LLM Evaluation Exercise        1   \n",
       "36  LLM Evaluation Exercise        1   \n",
       "37  LLM Evaluation Exercise        1   \n",
       "38  LLM Evaluation Exercise        1   \n",
       "39  LLM Evaluation Exercise        1   \n",
       "40  LLM Evaluation Exercise        1   \n",
       "41  LLM Evaluation Exercise        1   \n",
       "42  LLM Evaluation Exercise        1   \n",
       "43  LLM Evaluation Exercise        1   \n",
       "44  LLM Evaluation Exercise        1   \n",
       "45  LLM Evaluation Exercise        1   \n",
       "46  LLM Evaluation Exercise        1   \n",
       "47  LLM Evaluation Exercise        1   \n",
       "48  LLM Evaluation Exercise        1   \n",
       "49  LLM Evaluation Exercise        1   \n",
       "\n",
       "                                               traces  \n",
       "0   {'trace_id': 'trace_0001', 'user_query': 'Who ...  \n",
       "1   {'trace_id': 'trace_0002', 'user_query': 'Summ...  \n",
       "2   {'trace_id': 'trace_0003', 'user_query': 'Tran...  \n",
       "3   {'trace_id': 'trace_0004', 'user_query': 'Summ...  \n",
       "4   {'trace_id': 'trace_0005', 'user_query': 'Who ...  \n",
       "5   {'trace_id': 'trace_0006', 'user_query': 'Expl...  \n",
       "6   {'trace_id': 'trace_0007', 'user_query': 'Who ...  \n",
       "7   {'trace_id': 'trace_0008', 'user_query': 'Summ...  \n",
       "8   {'trace_id': 'trace_0009', 'user_query': 'What...  \n",
       "9   {'trace_id': 'trace_0010', 'user_query': 'Expl...  \n",
       "10  {'trace_id': 'trace_0011', 'user_query': 'Tran...  \n",
       "11  {'trace_id': 'trace_0012', 'user_query': 'What...  \n",
       "12  {'trace_id': 'trace_0013', 'user_query': 'What...  \n",
       "13  {'trace_id': 'trace_0014', 'user_query': 'Summ...  \n",
       "14  {'trace_id': 'trace_0015', 'user_query': 'Summ...  \n",
       "15  {'trace_id': 'trace_0016', 'user_query': 'What...  \n",
       "16  {'trace_id': 'trace_0017', 'user_query': 'Who ...  \n",
       "17  {'trace_id': 'trace_0018', 'user_query': 'What...  \n",
       "18  {'trace_id': 'trace_0019', 'user_query': 'Who ...  \n",
       "19  {'trace_id': 'trace_0020', 'user_query': 'Summ...  \n",
       "20  {'trace_id': 'trace_0021', 'user_query': 'Who ...  \n",
       "21  {'trace_id': 'trace_0022', 'user_query': 'Expl...  \n",
       "22  {'trace_id': 'trace_0023', 'user_query': 'Who ...  \n",
       "23  {'trace_id': 'trace_0024', 'user_query': 'Who ...  \n",
       "24  {'trace_id': 'trace_0025', 'user_query': 'Expl...  \n",
       "25  {'trace_id': 'trace_0026', 'user_query': 'Summ...  \n",
       "26  {'trace_id': 'trace_0027', 'user_query': 'Summ...  \n",
       "27  {'trace_id': 'trace_0028', 'user_query': 'Summ...  \n",
       "28  {'trace_id': 'trace_0029', 'user_query': 'Who ...  \n",
       "29  {'trace_id': 'trace_0030', 'user_query': 'What...  \n",
       "30  {'trace_id': 'trace_0031', 'user_query': 'Tran...  \n",
       "31  {'trace_id': 'trace_0032', 'user_query': 'Summ...  \n",
       "32  {'trace_id': 'trace_0033', 'user_query': 'Who ...  \n",
       "33  {'trace_id': 'trace_0034', 'user_query': 'Summ...  \n",
       "34  {'trace_id': 'trace_0035', 'user_query': 'Who ...  \n",
       "35  {'trace_id': 'trace_0036', 'user_query': 'Expl...  \n",
       "36  {'trace_id': 'trace_0037', 'user_query': 'Tran...  \n",
       "37  {'trace_id': 'trace_0038', 'user_query': 'Who ...  \n",
       "38  {'trace_id': 'trace_0039', 'user_query': 'What...  \n",
       "39  {'trace_id': 'trace_0040', 'user_query': 'What...  \n",
       "40  {'trace_id': 'trace_0041', 'user_query': 'Summ...  \n",
       "41  {'trace_id': 'trace_0042', 'user_query': 'Expl...  \n",
       "42  {'trace_id': 'trace_0043', 'user_query': 'Expl...  \n",
       "43  {'trace_id': 'trace_0044', 'user_query': 'Expl...  \n",
       "44  {'trace_id': 'trace_0045', 'user_query': 'Expl...  \n",
       "45  {'trace_id': 'trace_0046', 'user_query': 'Who ...  \n",
       "46  {'trace_id': 'trace_0047', 'user_query': 'Tran...  \n",
       "47  {'trace_id': 'trace_0048', 'user_query': 'Expl...  \n",
       "48  {'trace_id': 'trace_0049', 'user_query': 'Tran...  \n",
       "49  {'trace_id': 'trace_0050', 'user_query': 'Expl...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"llm_traces_large.json\")\n",
    "print(df.columns)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4979de6-f906-405a-b499-286f1080f4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trace_id': 'trace_0002',\n",
       " 'user_query': 'Summarize the plot of Inception in one sentence.',\n",
       " 'steps': [{'name': 'retrieval',\n",
       "   'latency_ms': 270,\n",
       "   'model': 'custom-small',\n",
       "   'temperature': 0.02,\n",
       "   'token_usage': {'prompt_tokens': 11, 'completion_tokens': 83},\n",
       "   'output_docs': [{'doc_id': 'doc_2_0_0',\n",
       "     'title': 'Doc 0',\n",
       "     'content': 'Random content snippet 524'},\n",
       "    {'doc_id': 'doc_2_0_1',\n",
       "     'title': 'Doc 1',\n",
       "     'content': 'Random content snippet 237'}]},\n",
       "  {'name': 'prompt_construction',\n",
       "   'latency_ms': 189,\n",
       "   'model': 'gpt-3.5',\n",
       "   'temperature': 0.91,\n",
       "   'token_usage': {'prompt_tokens': 28, 'completion_tokens': 60}},\n",
       "  {'name': 'prompt_construction',\n",
       "   'latency_ms': 220,\n",
       "   'model': 'gpt-3.5',\n",
       "   'temperature': 0.8,\n",
       "   'token_usage': {'prompt_tokens': 39, 'completion_tokens': 56}},\n",
       "  {'name': 'retrieval',\n",
       "   'latency_ms': 126,\n",
       "   'model': 'gpt-3.5',\n",
       "   'temperature': 0.9,\n",
       "   'token_usage': {'prompt_tokens': 31, 'completion_tokens': 81},\n",
       "   'output_docs': [{'doc_id': 'doc_2_3_0',\n",
       "     'title': 'Doc 0',\n",
       "     'content': 'Random content snippet 939'},\n",
       "    {'doc_id': 'doc_2_3_1',\n",
       "     'title': 'Doc 1',\n",
       "     'content': 'Random content snippet 270'},\n",
       "    {'doc_id': 'doc_2_3_2',\n",
       "     'title': 'Doc 2',\n",
       "     'content': 'Random content snippet 676'}]}],\n",
       " 'final_output': 'A thief enters dreams to steal secrets, but plants an idea instead.',\n",
       " 'metadata': {'user_id': 'u411',\n",
       "  'region': 'EU',\n",
       "  'timestamp': '2025-09-24T21:05:00Z'},\n",
       " 'metrics': {'faithfulness': 0.85, 'relevance': 0.99, 'cost_usd': 0.065}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"traces\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04465622-00e4-4f1c-82b5-0384498c7cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['project', 'version', 'traces'], dtype='object')\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>version</th>\n",
       "      <th>traces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'trace_id': 'trace_001', 'user_query': 'Who ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   project version  \\\n",
       "0  LLM Evaluation Exercise     1.0   \n",
       "\n",
       "                                              traces  \n",
       "0  [{'trace_id': 'trace_001', 'user_query': 'Who ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"llm_traces.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Flatten nested JSON\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "print(df.columns)\n",
    "print(df.size)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e1416b5-4718-42f0-9ee9-2d7a30c264ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['trace_id', 'user_query', 'steps', 'final_output', 'metadata.user_id',\n",
      "       'metadata.region', 'metadata.timestamp', 'metrics.faithfulness',\n",
      "       'metrics.relevance', 'metrics.cost_usd', 'final_output.fr',\n",
      "       'final_output.es', 'final_output.it', 'project', 'version'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>user_query</th>\n",
       "      <th>steps</th>\n",
       "      <th>final_output</th>\n",
       "      <th>metadata.user_id</th>\n",
       "      <th>metadata.region</th>\n",
       "      <th>metadata.timestamp</th>\n",
       "      <th>metrics.faithfulness</th>\n",
       "      <th>metrics.relevance</th>\n",
       "      <th>metrics.cost_usd</th>\n",
       "      <th>final_output.fr</th>\n",
       "      <th>final_output.es</th>\n",
       "      <th>final_output.it</th>\n",
       "      <th>project</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trace_001</td>\n",
       "      <td>Who won the 2018 World Cup?</td>\n",
       "      <td>[{'name': 'retrieval', 'latency_ms': 150, 'out...</td>\n",
       "      <td>France (2018 FIFA World Cup winner)</td>\n",
       "      <td>u123</td>\n",
       "      <td>EU</td>\n",
       "      <td>2025-09-24T20:15:00Z</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trace_002</td>\n",
       "      <td>Explain quantum entanglement simply.</td>\n",
       "      <td>[{'name': 'prompt_construction', 'latency_ms':...</td>\n",
       "      <td>Quantum entanglement means two particles behav...</td>\n",
       "      <td>u456</td>\n",
       "      <td>US</td>\n",
       "      <td>2025-09-24T20:16:00Z</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trace_003</td>\n",
       "      <td>Translate 'Hello World' into French, Spanish, ...</td>\n",
       "      <td>[{'name': 'llm_generation', 'model': 'gpt-4', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u789</td>\n",
       "      <td>APAC</td>\n",
       "      <td>2025-09-24T20:18:00Z</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>Bonjour le monde</td>\n",
       "      <td>Hola mundo</td>\n",
       "      <td>Ciao mondo</td>\n",
       "      <td>LLM Evaluation Exercise</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trace_id                                         user_query  \\\n",
       "0  trace_001                        Who won the 2018 World Cup?   \n",
       "1  trace_002               Explain quantum entanglement simply.   \n",
       "2  trace_003  Translate 'Hello World' into French, Spanish, ...   \n",
       "\n",
       "                                               steps  \\\n",
       "0  [{'name': 'retrieval', 'latency_ms': 150, 'out...   \n",
       "1  [{'name': 'prompt_construction', 'latency_ms':...   \n",
       "2  [{'name': 'llm_generation', 'model': 'gpt-4', ...   \n",
       "\n",
       "                                        final_output metadata.user_id  \\\n",
       "0                France (2018 FIFA World Cup winner)             u123   \n",
       "1  Quantum entanglement means two particles behav...             u456   \n",
       "2                                                NaN             u789   \n",
       "\n",
       "  metadata.region    metadata.timestamp  metrics.faithfulness  \\\n",
       "0              EU  2025-09-24T20:15:00Z                  1.00   \n",
       "1              US  2025-09-24T20:16:00Z                  0.92   \n",
       "2            APAC  2025-09-24T20:18:00Z                  1.00   \n",
       "\n",
       "   metrics.relevance  metrics.cost_usd   final_output.fr final_output.es  \\\n",
       "0               0.97            0.0025               NaN             NaN   \n",
       "1               0.95            0.0038               NaN             NaN   \n",
       "2               1.00            0.0012  Bonjour le monde      Hola mundo   \n",
       "\n",
       "  final_output.it                  project version  \n",
       "0             NaN  LLM Evaluation Exercise     1.0  \n",
       "1             NaN  LLM Evaluation Exercise     1.0  \n",
       "2      Ciao mondo  LLM Evaluation Exercise     1.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"llm_traces.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Flatten the `traces` list while keeping project + version\n",
    "df = pd.json_normalize(\n",
    "    data,\n",
    "    record_path=\"traces\",\n",
    "    meta=[\"project\", \"version\"]\n",
    ")\n",
    "\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aff12968-bc04-42c2-b0f2-d29f2b280214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>user_query</th>\n",
       "      <th>final_output</th>\n",
       "      <th>metadata.user_id</th>\n",
       "      <th>metadata.region</th>\n",
       "      <th>metadata.timestamp</th>\n",
       "      <th>metrics.faithfulness</th>\n",
       "      <th>metrics.relevance</th>\n",
       "      <th>metrics.cost_usd</th>\n",
       "      <th>final_output.fr</th>\n",
       "      <th>...</th>\n",
       "      <th>output_docs</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>output</th>\n",
       "      <th>token_usage.prompt_tokens</th>\n",
       "      <th>token_usage.completion_tokens</th>\n",
       "      <th>input</th>\n",
       "      <th>output.fr</th>\n",
       "      <th>output.es</th>\n",
       "      <th>output.it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trace_001</td>\n",
       "      <td>Who won the 2018 World Cup?</td>\n",
       "      <td>France (2018 FIFA World Cup winner)</td>\n",
       "      <td>u123</td>\n",
       "      <td>EU</td>\n",
       "      <td>2025-09-24T20:15:00Z</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 'doc1', 'title': '2018 FIFA Final', 'c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trace_001</td>\n",
       "      <td>Who won the 2018 World Cup?</td>\n",
       "      <td>France (2018 FIFA World Cup winner)</td>\n",
       "      <td>u123</td>\n",
       "      <td>EU</td>\n",
       "      <td>2025-09-24T20:15:00Z</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>France won the 2018 FIFA World Cup, beating Cr...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trace_002</td>\n",
       "      <td>Explain quantum entanglement simply.</td>\n",
       "      <td>Quantum entanglement means two particles behav...</td>\n",
       "      <td>u456</td>\n",
       "      <td>US</td>\n",
       "      <td>2025-09-24T20:16:00Z</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Explain in simple words: quantum entanglement...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Explain quantum entanglement simply.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trace_002</td>\n",
       "      <td>Explain quantum entanglement simply.</td>\n",
       "      <td>Quantum entanglement means two particles behav...</td>\n",
       "      <td>u456</td>\n",
       "      <td>US</td>\n",
       "      <td>2025-09-24T20:16:00Z</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Quantum entanglement is like having two dice t...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trace_003</td>\n",
       "      <td>Translate 'Hello World' into French, Spanish, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u789</td>\n",
       "      <td>APAC</td>\n",
       "      <td>2025-09-24T20:18:00Z</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>Bonjour le monde</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bonjour le monde</td>\n",
       "      <td>Hola mundo</td>\n",
       "      <td>Ciao mondo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    trace_id                                         user_query  \\\n",
       "0  trace_001                        Who won the 2018 World Cup?   \n",
       "1  trace_001                        Who won the 2018 World Cup?   \n",
       "2  trace_002               Explain quantum entanglement simply.   \n",
       "3  trace_002               Explain quantum entanglement simply.   \n",
       "4  trace_003  Translate 'Hello World' into French, Spanish, ...   \n",
       "\n",
       "                                        final_output metadata.user_id  \\\n",
       "0                France (2018 FIFA World Cup winner)             u123   \n",
       "1                France (2018 FIFA World Cup winner)             u123   \n",
       "2  Quantum entanglement means two particles behav...             u456   \n",
       "3  Quantum entanglement means two particles behav...             u456   \n",
       "4                                                NaN             u789   \n",
       "\n",
       "  metadata.region    metadata.timestamp  metrics.faithfulness  \\\n",
       "0              EU  2025-09-24T20:15:00Z                  1.00   \n",
       "1              EU  2025-09-24T20:15:00Z                  1.00   \n",
       "2              US  2025-09-24T20:16:00Z                  0.92   \n",
       "3              US  2025-09-24T20:16:00Z                  0.92   \n",
       "4            APAC  2025-09-24T20:18:00Z                  1.00   \n",
       "\n",
       "   metrics.relevance  metrics.cost_usd   final_output.fr  ...  \\\n",
       "0               0.97            0.0025               NaN  ...   \n",
       "1               0.97            0.0025               NaN  ...   \n",
       "2               0.95            0.0038               NaN  ...   \n",
       "3               0.95            0.0038               NaN  ...   \n",
       "4               1.00            0.0012  Bonjour le monde  ...   \n",
       "\n",
       "                                         output_docs  model temperature  \\\n",
       "0  [{'id': 'doc1', 'title': '2018 FIFA Final', 'c...    NaN         NaN   \n",
       "1                                                NaN  gpt-4         0.2   \n",
       "2                                                NaN    NaN         NaN   \n",
       "3                                                NaN  gpt-4         0.7   \n",
       "4                                                NaN  gpt-4         0.0   \n",
       "\n",
       "                                              output  \\\n",
       "0                                                NaN   \n",
       "1  France won the 2018 FIFA World Cup, beating Cr...   \n",
       "2   Explain in simple words: quantum entanglement...   \n",
       "3  Quantum entanglement is like having two dice t...   \n",
       "4                                                NaN   \n",
       "\n",
       "  token_usage.prompt_tokens  token_usage.completion_tokens  \\\n",
       "0                       NaN                            NaN   \n",
       "1                      60.0                           25.0   \n",
       "2                       NaN                            NaN   \n",
       "3                      45.0                           60.0   \n",
       "4                      30.0                           15.0   \n",
       "\n",
       "                                  input         output.fr   output.es  \\\n",
       "0                                   NaN               NaN         NaN   \n",
       "1                                   NaN               NaN         NaN   \n",
       "2  Explain quantum entanglement simply.               NaN         NaN   \n",
       "3                                   NaN               NaN         NaN   \n",
       "4                                   NaN  Bonjour le monde  Hola mundo   \n",
       "\n",
       "    output.it  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4  Ciao mondo  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Keep your original trace-level df\n",
    "df_steps = df.copy()\n",
    "\n",
    "# 2) Coerce 'steps' to list (handles None or single dict)\n",
    "df_steps[\"steps\"] = df_steps[\"steps\"].apply(\n",
    "    lambda x: [] if x is None\n",
    "    else ([x] if isinstance(x, dict) else x)\n",
    ")\n",
    "\n",
    "# 3) One row per step\n",
    "steps_long = (\n",
    "    df_steps\n",
    "      .explode(\"steps\")\n",
    "      .dropna(subset=[\"steps\"])\n",
    "      .reset_index(drop=True)      # <-- important for concat alignment\n",
    ")\n",
    "\n",
    "# (optional) If some entries aren't dicts, keep only dicts\n",
    "steps_long = steps_long[steps_long[\"steps\"].apply(lambda x: isinstance(x, dict))].reset_index(drop=True)\n",
    "\n",
    "# 4) Normalize the dict column and concat\n",
    "step_cols = pd.json_normalize(steps_long[\"steps\"], sep=\".\")\n",
    "steps_long = pd.concat(\n",
    "    [steps_long.drop(columns=\"steps\").reset_index(drop=True), step_cols],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "steps_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a767848e-00c6-435d-9c92-fb9d197305b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trace_id', 'user_query', 'final_output', 'metadata.user_id',\n",
       "       'metadata.region', 'metadata.timestamp', 'metrics.faithfulness',\n",
       "       'metrics.relevance', 'metrics.cost_usd', 'final_output.fr',\n",
       "       'final_output.es', 'final_output.it', 'project', 'version', 'name',\n",
       "       'latency_ms', 'output_docs', 'model', 'temperature', 'output',\n",
       "       'token_usage.prompt_tokens', 'token_usage.completion_tokens', 'input',\n",
       "       'output.fr', 'output.es', 'output.it'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_long.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe18993-7d7d-4f4d-a85c-592af8a3db75",
   "metadata": {},
   "source": [
    "## 0) Setup + helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc25a2e1-edcd-4a4e-8c10-0891d2ca8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# ---- Pretty inspection of DataFrames ----\n",
    "def peek(df, title, n=5, show_cols=True, show_index=False, show_dtypes=False):\n",
    "    print(f\"\\n===== {title} =====\")\n",
    "    print(\"shape:\", df.shape)\n",
    "    if show_index:\n",
    "        print(\"index is_unique:\", df.index.is_unique)\n",
    "    if show_cols:\n",
    "        print(\"columns:\", list(df.columns))\n",
    "    if show_dtypes:\n",
    "        print(\"\\ndtypes:\\n\", df.dtypes)\n",
    "    print(\"\\nhead:\\n\", df.head(n))\n",
    "\n",
    "# ---- Quick type profiler for any Python object ----\n",
    "def type_of(x):\n",
    "    return type(x).__name__\n",
    "\n",
    "def series_type_counts(s):\n",
    "    return s.apply(type_of).value_counts(dropna=False)\n",
    "\n",
    "# ---- Safe slice printer for long strings or big dicts ----\n",
    "def preview(obj, max_chars=800):\n",
    "    text = json.dumps(obj, indent=2, ensure_ascii=False) if not isinstance(obj, str) else obj\n",
    "    text = text if len(text) <= max_chars else text[:max_chars] + \"\\n... [truncated]\"\n",
    "    print(text)\n",
    "\n",
    "# ---- Recursive explorer: shows structure without assuming keys ----\n",
    "def explore(obj, max_items=5, depth=0, path=\"root\"):\n",
    "    indent = \"  \" * depth\n",
    "    if isinstance(obj, dict):\n",
    "        print(f\"{indent}{path}: dict with {len(obj)} keys\")\n",
    "        for i, (k, v) in enumerate(obj.items()):\n",
    "            if i >= max_items: \n",
    "                print(f\"{indent}  ... {len(obj)-max_items} more keys\")\n",
    "                break\n",
    "            explore(v, max_items=max_items, depth=depth+1, path=f\"{path}.{k}\")\n",
    "    elif isinstance(obj, list):\n",
    "        print(f\"{indent}{path}: list with {len(obj)} items\")\n",
    "        if obj:\n",
    "            # show first item structure\n",
    "            explore(obj[0], max_items=max_items, depth=depth+1, path=f\"{path}[0]\")\n",
    "        else:\n",
    "            print(f\"{indent}  (empty list)\")\n",
    "    else:\n",
    "        print(f\"{indent}{path}: {type_of(obj)} -> sample:\", str(obj)[:80])\n",
    "\n",
    "# ---- Find all list-of-dicts candidates (possible tables) ----\n",
    "def find_list_of_dicts(obj, path=\"root\", results=None):\n",
    "    if results is None:\n",
    "        results = []\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            find_list_of_dicts(v, f\"{path}.{k}\", results)\n",
    "    elif isinstance(obj, list):\n",
    "        if obj and isinstance(obj[0], dict):\n",
    "            results.append(path)\n",
    "        # also dive into first item to discover nested lists\n",
    "        if obj:\n",
    "            find_list_of_dicts(obj[0], f\"{path}[0]\", results)\n",
    "    return results\n",
    "\n",
    "# ---- Flatten a dict column in a DataFrame ----\n",
    "def flatten_dict_column(df, col, sep=\".\"):\n",
    "    \"\"\"Expand dicts in column `col` into new columns; keeps non-dicts as-is.\"\"\"\n",
    "    mask = df[col].apply(lambda x: isinstance(x, dict))\n",
    "    if not mask.any():\n",
    "        print(f\"Column '{col}' has no dict rows to flatten.\")\n",
    "        return df\n",
    "    expanded = pd.json_normalize(df.loc[mask, col], sep=sep)\n",
    "    expanded.index = df.index[mask]\n",
    "    out = df.drop(columns=[col]).join(expanded.add_prefix(f\"{col}{sep}\"))\n",
    "    return out\n",
    "\n",
    "# ---- Explode a list-of-dicts column into long rows ----\n",
    "def explode_list_of_dicts(df, col, sep=\".\"):\n",
    "    \"\"\"Explode list-of-dicts in `col` into long format and normalize.\"\"\"\n",
    "    if col not in df.columns:\n",
    "        raise KeyError(f\"Column '{col}' not found.\")\n",
    "    # coerce\n",
    "    coerced = df.copy()\n",
    "    coerced[col] = coerced[col].apply(\n",
    "        lambda x: [] if x is None else ([x] if isinstance(x, dict) else x)\n",
    "    )\n",
    "    # explode\n",
    "    long = coerced.explode(col).dropna(subset=[col]).reset_index(drop=True)\n",
    "    # normalize step dicts\n",
    "    mask_dict = long[col].apply(lambda x: isinstance(x, dict))\n",
    "    if mask_dict.any():\n",
    "        norm = pd.json_normalize(long.loc[mask_dict, col], sep=sep)\n",
    "        norm.index = long.index[mask_dict]\n",
    "        long = long.drop(columns=[col]).join(norm)\n",
    "    else:\n",
    "        # list of scalars; just keep it\n",
    "        long = long.rename(columns={col: f\"{col}_value\"})\n",
    "    return long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a430be17-4a40-4427-8c1e-2f006614144e",
   "metadata": {},
   "source": [
    "## 1) Read the JSON and understand its shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "897e8b2b-545d-4323-be18-f16fafed11f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw preview of the file:\n",
      "{\n",
      "    \"project\": \"LLM Evaluation Exercise\",\n",
      "    \"version\": \"1.0\",\n",
      "    \"traces\": [\n",
      "        {\n",
      "            \"trace_id\": \"trace_001\",\n",
      "            \"user_query\": \"Who won the 2018 World Cup?\",\n",
      "            \"metadata\": {\n",
      "                \"user_id\": \"u123\",\n",
      "                \"region\": \"EU\",\n",
      "                \"timestamp\": \"2025-09-24T20:15:00Z\"\n",
      "            },\n",
      "            \"steps\": [\n",
      "                {\n",
      "                    \"name\": \"retrieval\",\n",
      "                    \"latency_ms\": 150,\n",
      "                    \"output_docs\": [\n",
      "                        {\n",
      "                            \"id\": \"doc1\",\n",
      "                            \"title\": \"2018 FIFA Final\",\n",
      "                            \"content\": \"France defeated Croatia 4-2.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"id\": \"doc2\",\n",
      "                            \"title\": \"World Cup Summary\",\n",
      "                            \"content\": \"France crowned world champion 2018.\"\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"llm_generation\",\n",
      "                    \"model\": \"gpt-4\",\n",
      "                    \"temperature\": 0.2,\n",
      "                    \"latency_ms\": 310,\n",
      "                    \"token_usage\": {\n",
      "                        \"prompt_tokens\": 60,\n",
      "                        \"completion_tokens\": 25\n",
      "                    },\n",
      "                    \"output\": \"France won the 2018 FIFA World Cup, beating Croatia 4-2.\"\n",
      "                }\n",
      "            ],\n",
      "            \"final_output\": \"France (2018 FIFA World Cup winner)\",\n",
      "            \"metrics\": {\n",
      "                \"faithfulness\": 1.0,\n",
      "                \"relevance\": 0.97,\n",
      "                \"cost_usd\": 0.0025\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"trace_id\": \"trace_002\",\n",
      "            \"user_query\": \"Explain quantum entanglement simply.\",\n",
      "            \"metadata\": {\n",
      "                \"user_id\": \"u456\",\n",
      "                \"region\": \"US\",\n",
      "                \"timestamp\": \"2025-09-24T20:16:00Z\"\n",
      "            },\n",
      "            \"steps\": [\n",
      "                {\n",
      "                    \"name\": \"prompt_construction\",\n",
      "                    \"latency_ms\": 50,\n",
      "                    \"input\": \"Explain quantum entanglement simply.\",\n",
      "                    \"output\": \"Explain in simple words: quantum entanglement...\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"llm_generation\",\n",
      "                    \"model\": \"gpt-4\",\n",
      "                    \"temperature\": 0.7,\n",
      "                    \"latency_ms\": 400,\n",
      "                    \"token_usage\": {\n",
      "                        \"prompt_tokens\": 45,\n",
      "                        \"completion_tokens\": 60\n",
      "                    },\n",
      "                    \"output\": \"Quantum entanglement is like having two dice that always show the same number...\"\n",
      "                }\n",
      "            ],\n",
      "            \"final_output\": \"Quantum entanglement means two particles behave as one, no matter the distance.\",\n",
      "            \"metrics\": {\n",
      "                \"faithfulness\": 0.92,\n",
      "                \"relevance\": 0.95,\n",
      "                \"cost_usd\": 0.0038\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"trace_id\": \"trace_003\",\n",
      "            \"user_query\": \"Translate 'Hello World' into French, Spanish, and Italian.\",\n",
      "            \"metadata\": {\n",
      "                \"user_id\": \"u789\",\n",
      "                \"region\": \"APAC\",\n",
      "                \"timestamp\": \"2025-09-24T20:18:00Z\"\n",
      "            },\n",
      "            \"steps\": [\n",
      "                {\n",
      "                    \"name\": \"llm_generation\",\n",
      "                    \"model\": \"gpt-4\",\n",
      "                    \"temperature\": 0.0,\n",
      "                    \"latency_ms\": 200,\n",
      "                    \"token_usage\": {\n",
      "                        \"prompt_tokens\": 30,\n",
      "                        \"completion_tokens\": 15\n",
      "                    },\n",
      "                    \"output\": {\n",
      "                        \"fr\": \"Bonjour le monde\",\n",
      "                        \"es\": \"Hola mundo\",\n",
      "                        \"it\": \"Ciao mondo\"\n",
      "                    }\n",
      "                }\n",
      "            ],\n",
      "            \"final_output\": {\n",
      "                \"fr\": \"Bonjour le monde\",\n",
      "                \"es\": \"Hola mundo\",\n",
      "                \"it\": \"Ciao mondo\"\n",
      "            },\n",
      "            \"metrics\": {\n",
      "                \"faithfulness\": 1.0,\n",
      "                \"relevance\": 1.0,\n",
      "                \"cost_usd\": 0.0012\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Top-level Python type: dict\n"
     ]
    }
   ],
   "source": [
    "path = \"llm_traces.json\"  # adjust if needed\n",
    "\n",
    "# 1a) Load raw text (helps when debugging broken JSON)\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"Raw preview of the file:\")\n",
    "preview(raw_text, max_chars=6000)\n",
    "\n",
    "# 1b) Parse JSON into Python (dict/list/scalars)\n",
    "data = json.loads(raw_text)\n",
    "print(\"\\nTop-level Python type:\", type_of(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dfdfc8-7d8b-4fa1-a2bc-ecc46120daa2",
   "metadata": {},
   "source": [
    "## 2) Map the structure generically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0bd1680d-0ac9-4a55-996b-61774c864a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- High-level structure exploration ---\n",
      "root: dict with 3 keys\n",
      "  root.project: str -> sample: LLM Evaluation Exercise\n",
      "  root.version: str -> sample: 1.0\n",
      "  root.traces: list with 3 items\n",
      "    root.traces[0]: dict with 6 keys\n",
      "      root.traces[0].trace_id: str -> sample: trace_001\n",
      "      root.traces[0].user_query: str -> sample: Who won the 2018 World Cup?\n",
      "      root.traces[0].metadata: dict with 3 keys\n",
      "        root.traces[0].metadata.user_id: str -> sample: u123\n",
      "        root.traces[0].metadata.region: str -> sample: EU\n",
      "        root.traces[0].metadata.timestamp: str -> sample: 2025-09-24T20:15:00Z\n",
      "      root.traces[0].steps: list with 2 items\n",
      "        root.traces[0].steps[0]: dict with 3 keys\n",
      "          root.traces[0].steps[0].name: str -> sample: retrieval\n",
      "          root.traces[0].steps[0].latency_ms: int -> sample: 150\n",
      "          root.traces[0].steps[0].output_docs: list with 2 items\n",
      "            root.traces[0].steps[0].output_docs[0]: dict with 3 keys\n",
      "              root.traces[0].steps[0].output_docs[0].id: str -> sample: doc1\n",
      "              root.traces[0].steps[0].output_docs[0].title: str -> sample: 2018 FIFA Final\n",
      "              root.traces[0].steps[0].output_docs[0].content: str -> sample: France defeated Croatia 4-2.\n",
      "      root.traces[0].final_output: str -> sample: France (2018 FIFA World Cup winner)\n",
      "      root.traces[0].metrics: dict with 3 keys\n",
      "        root.traces[0].metrics.faithfulness: float -> sample: 1.0\n",
      "        root.traces[0].metrics.relevance: float -> sample: 0.97\n",
      "        root.traces[0].metrics.cost_usd: float -> sample: 0.0025\n",
      "\n",
      "--- Candidate list-of-dicts (potential tables) ---\n",
      "   root.traces\n",
      "   root.traces[0].steps\n",
      "   root.traces[0].steps[0].output_docs\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- High-level structure exploration ---\")\n",
    "explore(data, max_items=6)\n",
    "\n",
    "print(\"\\n--- Candidate list-of-dicts (potential tables) ---\")\n",
    "candidates = find_list_of_dicts(data)\n",
    "for c in sorted(set(candidates)):\n",
    "    print(\"  \", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc1b6d-abd6-4629-a47a-3c731285737c",
   "metadata": {},
   "source": [
    "## 3) Build a first table dynamically, based on what you find\n",
    "At this point, you have a first usable table (df0). It may still contain:\n",
    "\n",
    "\t•\tdict-like columns (flatten them),\n",
    "\t•\tlist-of-dicts columns (explode + normalize),\n",
    "\t•\tlist of scalars (explode if needed),\n",
    "\t•\tor mixed types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2aa333c0-240e-4087-bfd8-d8da67dfe296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Base table (safe) =====\n",
      "shape: (3, 15)\n",
      "columns: ['trace_id', 'user_query', 'steps', 'final_output', 'metadata.user_id', 'metadata.region', 'metadata.timestamp', 'metrics.faithfulness', 'metrics.relevance', 'metrics.cost_usd', 'final_output.fr', 'final_output.es', 'final_output.it', 'project', 'version']\n",
      "\n",
      "head:\n",
      "     trace_id                                         user_query  \\\n",
      "0  trace_001                        Who won the 2018 World Cup?   \n",
      "1  trace_002               Explain quantum entanglement simply.   \n",
      "2  trace_003  Translate 'Hello World' into French, Spanish, ...   \n",
      "\n",
      "                                               steps  \\\n",
      "0  [{'name': 'retrieval', 'latency_ms': 150, 'out...   \n",
      "1  [{'name': 'prompt_construction', 'latency_ms':...   \n",
      "2  [{'name': 'llm_generation', 'model': 'gpt-4', ...   \n",
      "\n",
      "                                        final_output metadata.user_id  \\\n",
      "0                France (2018 FIFA World Cup winner)             u123   \n",
      "1  Quantum entanglement means two particles behav...             u456   \n",
      "2                                                NaN             u789   \n",
      "\n",
      "  metadata.region    metadata.timestamp  metrics.faithfulness  \\\n",
      "0              EU  2025-09-24T20:15:00Z                  1.00   \n",
      "1              US  2025-09-24T20:16:00Z                  0.92   \n",
      "2            APAC  2025-09-24T20:18:00Z                  1.00   \n",
      "\n",
      "   metrics.relevance  metrics.cost_usd   final_output.fr final_output.es  \\\n",
      "0               0.97            0.0025               NaN             NaN   \n",
      "1               0.95            0.0038               NaN             NaN   \n",
      "2               1.00            0.0012  Bonjour le monde      Hola mundo   \n",
      "\n",
      "  final_output.it                  project version  \n",
      "0             NaN  LLM Evaluation Exercise     1.0  \n",
      "1             NaN  LLM Evaluation Exercise     1.0  \n",
      "2      Ciao mondo  LLM Evaluation Exercise     1.0  \n",
      "Base info: {'record_path': ['traces'], 'meta': ['project', 'version']}\n"
     ]
    }
   ],
   "source": [
    "def build_base_table(data, sep=\".\"):\n",
    "    # Case 1: top-level list\n",
    "    if isinstance(data, list):\n",
    "        if data and isinstance(data[0], dict):\n",
    "            return pd.json_normalize(data, sep=sep), {\"record_path\": [\"<top-level list>\"], \"meta\": []}\n",
    "        else:\n",
    "            return pd.DataFrame({\"value\": data}), {\"record_path\": None, \"meta\": []}\n",
    "\n",
    "    # Case 2: top-level dict\n",
    "    if isinstance(data, dict):\n",
    "        # collect top-level lists\n",
    "        top_lists = {k: v for k, v in data.items() if isinstance(v, list)}\n",
    "        # keep only list-of-dicts\n",
    "        lod_keys = [k for k, v in top_lists.items() if v and isinstance(v[0], dict)]\n",
    "        if lod_keys:\n",
    "            # choose the largest list-of-dicts; it's usually the records\n",
    "            chosen = max(lod_keys, key=lambda k: len(data[k]))\n",
    "            # meta: top-level non-list fields; safe to include\n",
    "            meta = [k for k in data.keys() if k != chosen and not isinstance(data[k], list)]\n",
    "            df = pd.json_normalize(\n",
    "                data,\n",
    "                record_path=[chosen],\n",
    "                meta=meta,\n",
    "                sep=sep,\n",
    "                errors=\"ignore\"   # tolerates missing meta keys\n",
    "            )\n",
    "            return df, {\"record_path\": [chosen], \"meta\": meta}\n",
    "        # No top-level list-of-dicts → just flatten the dict\n",
    "        return pd.json_normalize(data, sep=sep), {\"record_path\": None, \"meta\": []}\n",
    "\n",
    "    # Case 3: anything else (scalar etc.)\n",
    "    return pd.DataFrame({\"value\": [data]}), {\"record_path\": None, \"meta\": []}\n",
    "\n",
    "df0, base_info = build_base_table(data, sep=\".\")\n",
    "peek(df0, \"Base table (safe)\")\n",
    "print(\"Base info:\", base_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ce285-7f90-4abd-9f47-3b686d015c0f",
   "metadata": {},
   "source": [
    "## 4) Inspect which columns still hold nested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0d54861-ec97-465d-bca4-eca1e920f057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns containing nested objects/lists (first pass):\n",
      "- steps: {'list': 3}\n",
      "- final_output: {'str': 2, 'float': 1}\n",
      "- final_output.fr: {'float': 2, 'str': 1}\n",
      "- final_output.es: {'float': 2, 'str': 1}\n",
      "- final_output.it: {'float': 2, 'str': 1}\n"
     ]
    }
   ],
   "source": [
    "def type_of(x): return type(x).__name__\n",
    "def series_type_counts(s): return s.apply(type_of).value_counts(dropna=False)\n",
    "\n",
    "print(\"\\nColumns containing nested objects/lists (first pass):\")\n",
    "for col in df0.columns:\n",
    "    if df0[col].dtype == \"object\":\n",
    "        counts = series_type_counts(df0[col])\n",
    "        if any(t in counts for t in [\"dict\", \"list\"]) or len(counts) > 1:\n",
    "            print(f\"- {col}: {counts.to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc1ad23-59e2-4b01-a2f5-eed92ffb9d55",
   "metadata": {},
   "source": [
    "## 5) Flatten any dict columns (generic & repeatable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20fbd96d-7dba-4320-a539-a5f0a47027fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== After flattening dict-like columns (if any) =====\n",
      "shape: (3, 15)\n",
      "columns: ['trace_id', 'user_query', 'steps', 'final_output', 'metadata.user_id', 'metadata.region', 'metadata.timestamp', 'metrics.faithfulness', 'metrics.relevance', 'metrics.cost_usd', 'final_output.fr', 'final_output.es', 'final_output.it', 'project', 'version']\n",
      "\n",
      "head:\n",
      "     trace_id                                         user_query  \\\n",
      "0  trace_001                        Who won the 2018 World Cup?   \n",
      "1  trace_002               Explain quantum entanglement simply.   \n",
      "2  trace_003  Translate 'Hello World' into French, Spanish, ...   \n",
      "\n",
      "                                               steps  \\\n",
      "0  [{'name': 'retrieval', 'latency_ms': 150, 'out...   \n",
      "1  [{'name': 'prompt_construction', 'latency_ms':...   \n",
      "2  [{'name': 'llm_generation', 'model': 'gpt-4', ...   \n",
      "\n",
      "                                        final_output metadata.user_id  \\\n",
      "0                France (2018 FIFA World Cup winner)             u123   \n",
      "1  Quantum entanglement means two particles behav...             u456   \n",
      "2                                                NaN             u789   \n",
      "\n",
      "  metadata.region    metadata.timestamp  metrics.faithfulness  \\\n",
      "0              EU  2025-09-24T20:15:00Z                  1.00   \n",
      "1              US  2025-09-24T20:16:00Z                  0.92   \n",
      "2            APAC  2025-09-24T20:18:00Z                  1.00   \n",
      "\n",
      "   metrics.relevance  metrics.cost_usd   final_output.fr final_output.es  \\\n",
      "0               0.97            0.0025               NaN             NaN   \n",
      "1               0.95            0.0038               NaN             NaN   \n",
      "2               1.00            0.0012  Bonjour le monde      Hola mundo   \n",
      "\n",
      "  final_output.it                  project version  \n",
      "0             NaN  LLM Evaluation Exercise     1.0  \n",
      "1             NaN  LLM Evaluation Exercise     1.0  \n",
      "2      Ciao mondo  LLM Evaluation Exercise     1.0  \n"
     ]
    }
   ],
   "source": [
    "def flatten_dict_column(df, col, sep=\".\"):\n",
    "    \"\"\"Expand dicts in column `col` into new columns; keeps non-dicts as-is.\"\"\"\n",
    "    mask = df[col].apply(lambda x: isinstance(x, dict))\n",
    "    if not mask.any():\n",
    "        return df\n",
    "    expanded = pd.json_normalize(df.loc[mask, col], sep=sep)\n",
    "    expanded.index = df.index[mask]\n",
    "    out = df.drop(columns=[col]).join(expanded.add_prefix(f\"{col}{sep}\"))\n",
    "    return out\n",
    "\n",
    "# Example: flatten ALL dict-like columns in one go (run twice if needed)\n",
    "df1 = df0.copy()\n",
    "dict_cols = [c for c in df1.columns if df1[c].apply(lambda x: isinstance(x, dict)).any()]\n",
    "for c in dict_cols:\n",
    "    df1 = flatten_dict_column(df1, c, sep=\".\")\n",
    "peek(df1, \"After flattening dict-like columns (if any)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5101a-df77-4087-8a55-6ae1de96f9ac",
   "metadata": {},
   "source": [
    "## 6) Explode any list-of-dicts columns (e.g., steps) safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61098c6c-bf0c-4012-ab88-f2315e2310d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List-of-dicts columns: ['steps']\n",
      "\n",
      "===== After exploding list-of-dicts columns =====\n",
      "shape: (5, 26)\n",
      "columns: ['trace_id', 'user_query', 'final_output', 'metadata.user_id', 'metadata.region', 'metadata.timestamp', 'metrics.faithfulness', 'metrics.relevance', 'metrics.cost_usd', 'final_output.fr', 'final_output.es', 'final_output.it', 'project', 'version', 'name', 'latency_ms', 'output_docs', 'model', 'temperature', 'output', 'token_usage.prompt_tokens', 'token_usage.completion_tokens', 'input', 'output.fr', 'output.es', 'output.it']\n",
      "\n",
      "head:\n",
      "     trace_id                                         user_query  \\\n",
      "0  trace_001                        Who won the 2018 World Cup?   \n",
      "1  trace_001                        Who won the 2018 World Cup?   \n",
      "2  trace_002               Explain quantum entanglement simply.   \n",
      "3  trace_002               Explain quantum entanglement simply.   \n",
      "4  trace_003  Translate 'Hello World' into French, Spanish, ...   \n",
      "\n",
      "                                        final_output metadata.user_id  \\\n",
      "0                France (2018 FIFA World Cup winner)             u123   \n",
      "1                France (2018 FIFA World Cup winner)             u123   \n",
      "2  Quantum entanglement means two particles behav...             u456   \n",
      "3  Quantum entanglement means two particles behav...             u456   \n",
      "4                                                NaN             u789   \n",
      "\n",
      "  metadata.region    metadata.timestamp  metrics.faithfulness  \\\n",
      "0              EU  2025-09-24T20:15:00Z                  1.00   \n",
      "1              EU  2025-09-24T20:15:00Z                  1.00   \n",
      "2              US  2025-09-24T20:16:00Z                  0.92   \n",
      "3              US  2025-09-24T20:16:00Z                  0.92   \n",
      "4            APAC  2025-09-24T20:18:00Z                  1.00   \n",
      "\n",
      "   metrics.relevance  metrics.cost_usd   final_output.fr  ...  \\\n",
      "0               0.97            0.0025               NaN  ...   \n",
      "1               0.97            0.0025               NaN  ...   \n",
      "2               0.95            0.0038               NaN  ...   \n",
      "3               0.95            0.0038               NaN  ...   \n",
      "4               1.00            0.0012  Bonjour le monde  ...   \n",
      "\n",
      "                                         output_docs  model temperature  \\\n",
      "0  [{'id': 'doc1', 'title': '2018 FIFA Final', 'c...    NaN         NaN   \n",
      "1                                                NaN  gpt-4         0.2   \n",
      "2                                                NaN    NaN         NaN   \n",
      "3                                                NaN  gpt-4         0.7   \n",
      "4                                                NaN  gpt-4         0.0   \n",
      "\n",
      "                                              output  \\\n",
      "0                                                NaN   \n",
      "1  France won the 2018 FIFA World Cup, beating Cr...   \n",
      "2   Explain in simple words: quantum entanglement...   \n",
      "3  Quantum entanglement is like having two dice t...   \n",
      "4                                                NaN   \n",
      "\n",
      "  token_usage.prompt_tokens  token_usage.completion_tokens  \\\n",
      "0                       NaN                            NaN   \n",
      "1                      60.0                           25.0   \n",
      "2                       NaN                            NaN   \n",
      "3                      45.0                           60.0   \n",
      "4                      30.0                           15.0   \n",
      "\n",
      "                                  input         output.fr   output.es  \\\n",
      "0                                   NaN               NaN         NaN   \n",
      "1                                   NaN               NaN         NaN   \n",
      "2  Explain quantum entanglement simply.               NaN         NaN   \n",
      "3                                   NaN               NaN         NaN   \n",
      "4                                   NaN  Bonjour le monde  Hola mundo   \n",
      "\n",
      "    output.it  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4  Ciao mondo  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "def explode_list_of_dicts(df, col, sep=\".\"):\n",
    "    \"\"\"Explode list-of-dicts in `col` into long format and normalize.\"\"\"\n",
    "    if col not in df.columns:\n",
    "        raise KeyError(f\"Column '{col}' not found.\")\n",
    "    out = df.copy()\n",
    "    # coerce to list\n",
    "    out[col] = out[col].apply(lambda x: [] if x is None else ([x] if isinstance(x, dict) else x))\n",
    "    # explode\n",
    "    out = out.explode(col).dropna(subset=[col]).reset_index(drop=True)\n",
    "    # normalize dict rows\n",
    "    mask = out[col].apply(lambda x: isinstance(x, dict))\n",
    "    if mask.any():\n",
    "        norm = pd.json_normalize(out.loc[mask, col], sep=sep)\n",
    "        norm.index = out.index[mask]\n",
    "        out = out.drop(columns=[col]).join(norm)   # join aligned by index\n",
    "    else:\n",
    "        # list of scalars → keep as a value column\n",
    "        out = out.rename(columns={col: f\"{col}_value\"})\n",
    "    return out\n",
    "\n",
    "# Identify list-of-dicts columns\n",
    "lod_cols = [\n",
    "    c for c in df1.columns\n",
    "    if df1[c].apply(lambda x: isinstance(x, list) and len(x) > 0 and isinstance(x[0], dict) if isinstance(x, list) else False).any()\n",
    "]\n",
    "print(\"List-of-dicts columns:\", lod_cols)\n",
    "\n",
    "# Explode them one by one (start with the most important, e.g., 'steps')\n",
    "df2 = df1.copy()\n",
    "for c in lod_cols:\n",
    "    df2 = explode_list_of_dicts(df2, c, sep=\".\")\n",
    "peek(df2, \"After exploding list-of-dicts columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8930ddee-b348-4398-bd5c-d76feef7debd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>user_query</th>\n",
       "      <th>final_output</th>\n",
       "      <th>metadata.user_id</th>\n",
       "      <th>metadata.region</th>\n",
       "      <th>metadata.timestamp</th>\n",
       "      <th>metrics.faithfulness</th>\n",
       "      <th>metrics.relevance</th>\n",
       "      <th>metrics.cost_usd</th>\n",
       "      <th>final_output.fr</th>\n",
       "      <th>...</th>\n",
       "      <th>output_docs</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>output</th>\n",
       "      <th>token_usage.prompt_tokens</th>\n",
       "      <th>token_usage.completion_tokens</th>\n",
       "      <th>input</th>\n",
       "      <th>output.fr</th>\n",
       "      <th>output.es</th>\n",
       "      <th>output.it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trace_001</td>\n",
       "      <td>Who won the 2018 World Cup?</td>\n",
       "      <td>France (2018 FIFA World Cup winner)</td>\n",
       "      <td>u123</td>\n",
       "      <td>EU</td>\n",
       "      <td>2025-09-24T20:15:00Z</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 'doc1', 'title': '2018 FIFA Final', 'c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trace_001</td>\n",
       "      <td>Who won the 2018 World Cup?</td>\n",
       "      <td>France (2018 FIFA World Cup winner)</td>\n",
       "      <td>u123</td>\n",
       "      <td>EU</td>\n",
       "      <td>2025-09-24T20:15:00Z</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>France won the 2018 FIFA World Cup, beating Cr...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trace_002</td>\n",
       "      <td>Explain quantum entanglement simply.</td>\n",
       "      <td>Quantum entanglement means two particles behav...</td>\n",
       "      <td>u456</td>\n",
       "      <td>US</td>\n",
       "      <td>2025-09-24T20:16:00Z</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Explain in simple words: quantum entanglement...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Explain quantum entanglement simply.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trace_002</td>\n",
       "      <td>Explain quantum entanglement simply.</td>\n",
       "      <td>Quantum entanglement means two particles behav...</td>\n",
       "      <td>u456</td>\n",
       "      <td>US</td>\n",
       "      <td>2025-09-24T20:16:00Z</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Quantum entanglement is like having two dice t...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trace_003</td>\n",
       "      <td>Translate 'Hello World' into French, Spanish, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u789</td>\n",
       "      <td>APAC</td>\n",
       "      <td>2025-09-24T20:18:00Z</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>Bonjour le monde</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bonjour le monde</td>\n",
       "      <td>Hola mundo</td>\n",
       "      <td>Ciao mondo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    trace_id                                         user_query  \\\n",
       "0  trace_001                        Who won the 2018 World Cup?   \n",
       "1  trace_001                        Who won the 2018 World Cup?   \n",
       "2  trace_002               Explain quantum entanglement simply.   \n",
       "3  trace_002               Explain quantum entanglement simply.   \n",
       "4  trace_003  Translate 'Hello World' into French, Spanish, ...   \n",
       "\n",
       "                                        final_output metadata.user_id  \\\n",
       "0                France (2018 FIFA World Cup winner)             u123   \n",
       "1                France (2018 FIFA World Cup winner)             u123   \n",
       "2  Quantum entanglement means two particles behav...             u456   \n",
       "3  Quantum entanglement means two particles behav...             u456   \n",
       "4                                                NaN             u789   \n",
       "\n",
       "  metadata.region    metadata.timestamp  metrics.faithfulness  \\\n",
       "0              EU  2025-09-24T20:15:00Z                  1.00   \n",
       "1              EU  2025-09-24T20:15:00Z                  1.00   \n",
       "2              US  2025-09-24T20:16:00Z                  0.92   \n",
       "3              US  2025-09-24T20:16:00Z                  0.92   \n",
       "4            APAC  2025-09-24T20:18:00Z                  1.00   \n",
       "\n",
       "   metrics.relevance  metrics.cost_usd   final_output.fr  ...  \\\n",
       "0               0.97            0.0025               NaN  ...   \n",
       "1               0.97            0.0025               NaN  ...   \n",
       "2               0.95            0.0038               NaN  ...   \n",
       "3               0.95            0.0038               NaN  ...   \n",
       "4               1.00            0.0012  Bonjour le monde  ...   \n",
       "\n",
       "                                         output_docs  model temperature  \\\n",
       "0  [{'id': 'doc1', 'title': '2018 FIFA Final', 'c...    NaN         NaN   \n",
       "1                                                NaN  gpt-4         0.2   \n",
       "2                                                NaN    NaN         NaN   \n",
       "3                                                NaN  gpt-4         0.7   \n",
       "4                                                NaN  gpt-4         0.0   \n",
       "\n",
       "                                              output  \\\n",
       "0                                                NaN   \n",
       "1  France won the 2018 FIFA World Cup, beating Cr...   \n",
       "2   Explain in simple words: quantum entanglement...   \n",
       "3  Quantum entanglement is like having two dice t...   \n",
       "4                                                NaN   \n",
       "\n",
       "  token_usage.prompt_tokens  token_usage.completion_tokens  \\\n",
       "0                       NaN                            NaN   \n",
       "1                      60.0                           25.0   \n",
       "2                       NaN                            NaN   \n",
       "3                      45.0                           60.0   \n",
       "4                      30.0                           15.0   \n",
       "\n",
       "                                  input         output.fr   output.es  \\\n",
       "0                                   NaN               NaN         NaN   \n",
       "1                                   NaN               NaN         NaN   \n",
       "2  Explain quantum entanglement simply.               NaN         NaN   \n",
       "3                                   NaN               NaN         NaN   \n",
       "4                                   NaN  Bonjour le monde  Hola mundo   \n",
       "\n",
       "    output.it  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4  Ciao mondo  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01cd82bd-b9a0-4e93-ab92-2459f7283ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('json_flattened.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4118a830-4e8c-44a8-a6d5-f6daebc1f988",
   "metadata": {},
   "source": [
    "## 7) (Optional) Iterate until flat enough + light cleanups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eebddf-7f22-4ff5-8fe3-ec76c3828ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1b00bfc-cf79-41c5-ba8e-831f08d10993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining nested candidates:\n",
      "- final_output: {'str': 4, 'float': 1}\n",
      "- final_output.fr: {'float': 4, 'str': 1}\n",
      "- final_output.es: {'float': 4, 'str': 1}\n",
      "- final_output.it: {'float': 4, 'str': 1}\n",
      "- output_docs: {'float': 4, 'list': 1}\n",
      "- model: {'str': 3, 'float': 2}\n",
      "- output: {'str': 3, 'float': 2}\n",
      "- input: {'float': 4, 'str': 1}\n",
      "- output.fr: {'float': 4, 'str': 1}\n",
      "- output.es: {'float': 4, 'str': 1}\n",
      "- output.it: {'float': 4, 'str': 1}\n",
      "\n",
      "===== Final working table (flat enough for analysis) =====\n",
      "shape: (5, 26)\n",
      "columns: ['trace_id', 'user_query', 'final_output', 'metadata.user_id', 'metadata.region', 'metadata.timestamp', 'metrics.faithfulness', 'metrics.relevance', 'metrics.cost_usd', 'final_output.fr', 'final_output.es', 'final_output.it', 'project', 'version', 'name', 'latency_ms', 'output_docs', 'model', 'temperature', 'output', 'token_usage.prompt_tokens', 'token_usage.completion_tokens', 'input', 'output.fr', 'output.es', 'output.it']\n",
      "\n",
      "dtypes:\n",
      " trace_id                                      object\n",
      "user_query                                    object\n",
      "final_output                                  object\n",
      "metadata.user_id                              object\n",
      "metadata.region                               object\n",
      "metadata.timestamp               datetime64[ns, UTC]\n",
      "metrics.faithfulness                         float64\n",
      "metrics.relevance                            float64\n",
      "metrics.cost_usd                             float64\n",
      "final_output.fr                               object\n",
      "final_output.es                               object\n",
      "final_output.it                               object\n",
      "project                                       object\n",
      "version                                      float64\n",
      "name                                          object\n",
      "latency_ms                                     int64\n",
      "output_docs                                   object\n",
      "model                                         object\n",
      "temperature                                  float64\n",
      "output                                        object\n",
      "token_usage.prompt_tokens                    float64\n",
      "token_usage.completion_tokens                float64\n",
      "input                                         object\n",
      "output.fr                                     object\n",
      "output.es                                     object\n",
      "output.it                                     object\n",
      "dtype: object\n",
      "\n",
      "head:\n",
      "     trace_id                                         user_query  \\\n",
      "0  trace_001                        Who won the 2018 World Cup?   \n",
      "1  trace_001                        Who won the 2018 World Cup?   \n",
      "2  trace_002               Explain quantum entanglement simply.   \n",
      "3  trace_002               Explain quantum entanglement simply.   \n",
      "4  trace_003  Translate 'Hello World' into French, Spanish, ...   \n",
      "\n",
      "                                        final_output metadata.user_id  \\\n",
      "0                France (2018 FIFA World Cup winner)             u123   \n",
      "1                France (2018 FIFA World Cup winner)             u123   \n",
      "2  Quantum entanglement means two particles behav...             u456   \n",
      "3  Quantum entanglement means two particles behav...             u456   \n",
      "4                                                NaN             u789   \n",
      "\n",
      "  metadata.region        metadata.timestamp  metrics.faithfulness  \\\n",
      "0              EU 2025-09-24 20:15:00+00:00                  1.00   \n",
      "1              EU 2025-09-24 20:15:00+00:00                  1.00   \n",
      "2              US 2025-09-24 20:16:00+00:00                  0.92   \n",
      "3              US 2025-09-24 20:16:00+00:00                  0.92   \n",
      "4            APAC 2025-09-24 20:18:00+00:00                  1.00   \n",
      "\n",
      "   metrics.relevance  metrics.cost_usd   final_output.fr  ...  \\\n",
      "0               0.97            0.0025               NaN  ...   \n",
      "1               0.97            0.0025               NaN  ...   \n",
      "2               0.95            0.0038               NaN  ...   \n",
      "3               0.95            0.0038               NaN  ...   \n",
      "4               1.00            0.0012  Bonjour le monde  ...   \n",
      "\n",
      "                                         output_docs  model temperature  \\\n",
      "0  [{'id': 'doc1', 'title': '2018 FIFA Final', 'c...    NaN         NaN   \n",
      "1                                                NaN  gpt-4         0.2   \n",
      "2                                                NaN    NaN         NaN   \n",
      "3                                                NaN  gpt-4         0.7   \n",
      "4                                                NaN  gpt-4         0.0   \n",
      "\n",
      "                                              output  \\\n",
      "0                                                NaN   \n",
      "1  France won the 2018 FIFA World Cup, beating Cr...   \n",
      "2   Explain in simple words: quantum entanglement...   \n",
      "3  Quantum entanglement is like having two dice t...   \n",
      "4                                                NaN   \n",
      "\n",
      "  token_usage.prompt_tokens  token_usage.completion_tokens  \\\n",
      "0                       NaN                            NaN   \n",
      "1                      60.0                           25.0   \n",
      "2                       NaN                            NaN   \n",
      "3                      45.0                           60.0   \n",
      "4                      30.0                           15.0   \n",
      "\n",
      "                                  input         output.fr   output.es  \\\n",
      "0                                   NaN               NaN         NaN   \n",
      "1                                   NaN               NaN         NaN   \n",
      "2  Explain quantum entanglement simply.               NaN         NaN   \n",
      "3                                   NaN               NaN         NaN   \n",
      "4                                   NaN  Bonjour le monde  Hola mundo   \n",
      "\n",
      "    output.it  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4  Ciao mondo  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/05g602bs69j6y91p_fdnv62r0000gn/T/ipykernel_35668/2043900189.py:13: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df2[c] = pd.to_numeric(df2[c], errors=\"ignore\")\n",
      "/var/folders/vp/05g602bs69j6y91p_fdnv62r0000gn/T/ipykernel_35668/2043900189.py:19: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  df2[c] = pd.to_datetime(df2[c], errors=\"ignore\")\n"
     ]
    }
   ],
   "source": [
    "# Find remaining nested columns and repeat 5/6 as needed\n",
    "print(\"\\nRemaining nested candidates:\")\n",
    "for col in df2.columns:\n",
    "    if df2[col].dtype == \"object\":\n",
    "        counts = series_type_counts(df2[col])\n",
    "        if any(t in counts for t in [\"dict\", \"list\"]) or len(counts) > 1:\n",
    "            print(f\"- {col}: {counts.to_dict()}\")\n",
    "\n",
    "# Example numeric + datetime coercions\n",
    "maybe_numeric = [c for c in df2.columns if df2[c].dtype == \"object\"]\n",
    "for c in maybe_numeric:\n",
    "    # try numeric; if it fails it stays object\n",
    "    df2[c] = pd.to_numeric(df2[c], errors=\"ignore\")\n",
    "\n",
    "# ISO-ish timestamps\n",
    "for c in df2.columns:\n",
    "    if df2[c].dtype == \"object\" and df2[c].astype(str).str.contains(r\"T\\d{2}:\\d{2}\", na=False).any():\n",
    "        try:\n",
    "            df2[c] = pd.to_datetime(df2[c], errors=\"ignore\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "peek(df2, \"Final working table (flat enough for analysis)\", show_dtypes=True)\n",
    "# df2.to_csv(\"final_flat_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee052bfa-7cd2-4237-a682-3b597b4f6687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
